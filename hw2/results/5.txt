Using CPU
read in 175181 lines from 30 files in directory books/
INFO: had to represent 471916/3401907 (0.1387) tokens as unk with vocab limit 3000
INFO: cut off 0 sentences at len 830 before true ending
INFO: encoded 175181 sentences without regard to order
len 3752269
Epoch 0
train loss : 4.50139653423045 | train acc: 0.23398130761351998
val loss : 4.2052199407057325 | val acc: 0.26598011363636365
saving word vec to  ./saved/learned_word_vectors.txt
Saving word vectors to file...
Loading vectors from file './saved/learned_word_vectors.txt'...
... done loading vectors
Evaluating downstream performance on analogy task over 1309 analogies...
...Total performance across all 1309 analogies: 0.0008 (Exact); 0.0053 (MRR); 189 (MR)
...Analogy performance across 969 "sem" relation types: 0.0010 (Exact); 0.0049 (MRR); 202 (MR)
	relation	N	exact	MRR	MR
	capitals	1	0.0000	0.0042	236
	binary_gender	12	0.0000	0.0504	20
	antonym	54	0.0000	0.0019	524
	member	4	0.0000	0.0006	1772
	hypernomy	542	0.0018	0.0051	198
	similar	117	0.0000	0.0033	306
	partof	29	0.0000	0.0017	598
	instanceof	9	0.0000	0.0023	437
	derivedfrom	133	0.0000	0.0050	201
	hascontext	32	0.0000	0.0038	264
	relatedto	10	0.0000	0.0015	671
	attributeof	11	0.0000	0.0053	190
	causes	6	0.0000	0.0017	600
	entails	9	0.0000	0.0016	609
...Analogy performance across 340 "syn" relation types: 0.0000 (Exact); 0.0063 (MRR); 159 (MR)
	relation	N	exact	MRR	MR
	adj_adv	22	0.0000	0.0269	37
	comparative	7	0.0000	0.0094	107
	superlative	3	0.0000	0.0056	178
	present_participle	62	0.0000	0.0033	305
	denonym	2	0.0000	0.0021	478
	past_tense	64	0.0000	0.0070	142
	plural_nouns	107	0.0000	0.0059	171
	plural_verbs	73	0.0000	0.0025	403
saving model to  ./saved/model.ckpt
Epoch 1
train loss : 4.080508105915209 | train acc: 0.26832590047797883
Epoch 2
train loss : 4.01667200272789 | train acc: 0.2711262909696142
Epoch 3
train loss : 3.9845914458284284 | train acc: 0.27227776118129055
Epoch 4
train loss : 3.963145342439708 | train acc: 0.2729147106520997
Epoch 5
